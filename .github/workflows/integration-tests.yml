name: Integration Tests

on:
  pull_request_target:
    branches: [main]

jobs:
  authorization-check:
    permissions: read-all
    runs-on: ubuntu-latest
    outputs:
      approval-env: ${{ steps.collab-check.outputs.result }}
    steps:
      - name: Collaborator Check
        uses: actions/github-script@v7
        id: collab-check
        with:
          result-encoding: string
          script: |
            try {
              const permissionResponse = await github.rest.repos.getCollaboratorPermissionLevel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                username: context.payload.pull_request.user.login,
              });
              const permission = permissionResponse.data.permission;
              const hasWriteAccess = ['write', 'admin'].includes(permission);
              if (!hasWriteAccess) {
                console.log(`User ${context.payload.pull_request.user.login} does not have write access (permission: ${permission})`);
                return "manual-approval"
              } else {
                console.log(`Verified ${context.payload.pull_request.user.login} has write access. Auto Approving.`)
                return "auto-approve"
              }
            } catch (error) {
              console.log(`${context.payload.pull_request.user.login} does not have write access. Requiring Manual Approval.`)
              return "manual-approval"
            }

  check-access-and-test:
    runs-on: ubuntu-latest
    needs: authorization-check
    environment: ${{ needs.authorization-check.outputs.approval-env }}
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        pyspark-version: ['3.1.3', '3.2.4', '3.3.4', '3.4.3', '3.5.1']
        exclude:
          - python-version: '3.10'
            pyspark-version: '3.1.3'
          - python-version: '3.11'
            pyspark-version: '3.1.3'
          - python-version: '3.11'
            pyspark-version: '3.2.4'
          - python-version: '3.12'
            pyspark-version: '3.1.3'
          - python-version: '3.12'
            pyspark-version: '3.2.4'
          - python-version: '3.12'
            pyspark-version: '3.3.4'
    permissions:
      id-token: write
      pull-requests: read
      contents: read
      actions: read
    steps:
      - name: Checkout head commit
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Set up JDK 11
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'
          cache: 'sbt'

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyspark==${{ matrix.pyspark-version }}
          pip install --upgrade boto3
          pip install tox tox-gh-actions

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: us-west-2
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: GithubSession

      - name: Build and test Scala SDK
        run: |
          cd scala-spark-sdk
          sbt -DSPARK_VERSION=${{ matrix.pyspark-version }} \
              scalafmtCheckAll jacoco

      - name: Package and test PySpark SDK
        env:
          PYSPARK_VERSION: ${{ matrix.pyspark-version }}
        run: |
          export SPARK_BUILD_VERSION=$(echo "${{ matrix.pyspark-version }}" | cut -d. -f1,2)
          cd pyspark-sdk
          python setup.py sdist
          tox

      - name: Run Integration Tests
        run: |
          cd pyspark-sdk/integration_test
          chmod +x run-spark-integration-test
          ./run-spark-integration-test