name: Integration Tests

on:
  workflow_run:
    workflows: [Build]
    types: [completed]

jobs:
  test:
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success'
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        pyspark-version: ['3.2.4', '3.3.4', '3.4.3', '3.5.1']
        exclude:
          - python-version: '3.11'
            pyspark-version: '3.2.4'
          - python-version: '3.12'
            pyspark-version: '3.2.4'
          - python-version: '3.12'
            pyspark-version: '3.3.4'
    permissions:
      pull-requests: write
      id-token: write
      contents: read
      actions: read

    steps:
      - uses: actions/checkout@v4

      - name: Set up JDK 11
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade boto3
          pip install pyspark==${{ matrix.pyspark-version }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: us-west-2
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: GithubSession

      - name: Download Build Artifacts
        uses: actions/github-script@v7
        with:
          script: |
            const expectedName = `processedArtifacts-py${{ matrix.python-version }}-spark${{ matrix.pyspark-version }}`;
            
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: ${{ github.event.workflow_run.id }},
            });
            
            const match = artifacts.data.artifacts.find(a => a.name === expectedName);
            if (!match) {
              const available = artifacts.data.artifacts.map(a => a.name).join(', ');
              throw new Error(`Artifact '${expectedName}' not found. Available: ${available}`);
            }
            
            const download = await github.rest.actions.downloadArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: match.id,
              archive_format: 'zip',
            });
            
            const fs = require('fs');
            fs.writeFileSync('${{ github.workspace }}/processedArtifacts.zip', Buffer.from(download.data));

      - name: Run Integration Tests
        env:
          PYSPARK_VERSION: ${{ matrix.pyspark-version }}
        run: |
          mkdir -p artifacts
          unzip processedArtifacts.zip -d artifacts
          cd artifacts/integration_test
          chmod +x run-spark-integration-test
          ./run-spark-integration-test